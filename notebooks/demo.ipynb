{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HR Interview Orchestrator Demo ğŸ¯\n",
        "\n",
        "**AI-Powered Candidate Screening & Interview Automation**\n",
        "\n",
        "This notebook demonstrates the key features of the HR Interview Orchestrator system:\n",
        "- Job description parsing and validation\n",
        "- Candidate resume analysis\n",
        "- Interview question generation\n",
        "- Complete hiring workflow automation\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "parent_dir = Path.cwd().parent\n",
        "sys.path.insert(0, str(parent_dir))\n",
        "\n",
        "try:\n",
        "    # Import HR Orchestrator components\n",
        "    from src.tools.mcp_tool import (\n",
        "        parse_job_description_internal, \n",
        "        validate_job_description_quality,\n",
        "        job_description_tool\n",
        "    )\n",
        "    from src.tools.parser import parse_resume_to_struct, load_text\n",
        "    from src.agents import _score_candidate\n",
        "    from src.state import JD, Candidate\n",
        "    from src.tools.retriever import LocalQuestionBank\n",
        "    from src.config import config\n",
        "\n",
        "    print(\"âœ… HR Interview Orchestrator components loaded successfully!\")\n",
        "    print(f\"ğŸ“ Working directory: {Path.cwd()}\")\n",
        "    print(f\"ğŸ¢ Company: {config.COMPANY_NAME}\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"âš ï¸ Import error: {e}\")\n",
        "    print(\"ğŸ’¡ This notebook should be run from the 'notebooks' directory\")\n",
        "    print(\"ğŸ“ Make sure the parent directory contains the 'src' folder\")\n",
        "    print(\"ğŸ”§ You may need to install dependencies: pip install -r requirements.txt\")\n",
        "    \n",
        "    # Show current directory structure for debugging\n",
        "    print(f\"\\nğŸ“‹ Current directory: {Path.cwd()}\")\n",
        "    print(f\"ğŸ“‹ Parent directory: {parent_dir}\")\n",
        "    print(f\"ğŸ“‹ Looking for: {parent_dir / 'src'}\")\n",
        "    print(f\"ğŸ“‹ Src exists: {(parent_dir / 'src').exists()}\")\n",
        "    \n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“„ Job Description Analysis\n",
        "\n",
        "Let's start by analyzing a job description using our internal MCP tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample job description\n",
        "sample_jd = \"\"\"\n",
        "# Senior Full Stack Developer\n",
        "\n",
        "**Location:** San Francisco, CA / Remote\n",
        "\n",
        "**About the Role:**\n",
        "We're looking for an experienced Full Stack Developer to join our growing team.\n",
        "\n",
        "**Requirements:**\n",
        "- 5+ years of React and TypeScript experience\n",
        "- Strong Node.js and Express.js background\n",
        "- Experience with PostgreSQL or MongoDB\n",
        "- Docker and AWS deployment experience\n",
        "- Test-driven development (Jest, Cypress)\n",
        "\n",
        "**Nice to Have:**\n",
        "- GraphQL experience\n",
        "- Kubernetes knowledge\n",
        "- Microservices architecture\n",
        "- Team leadership experience\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ” Analyzing Job Description...\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Parse the job description\n",
        "jd_data = parse_job_description_internal(sample_jd, include_metadata=True)\n",
        "\n",
        "print(f\"ğŸ“‹ Title: {jd_data['title']}\")\n",
        "print(f\"ğŸ“ Location: {jd_data['location']}\")\n",
        "print(f\"âœ… Must-haves: {len(jd_data['must_haves'])} requirements\")\n",
        "print(f\"â­ Nice-haves: {len(jd_data['nice_haves'])} preferences\")\n",
        "print(f\"ğŸ“Š Status: {jd_data['parsing_status']}\")\n",
        "\n",
        "# Display requirements\n",
        "print(\"\\nğŸ”§ Required Skills:\")\n",
        "for i, skill in enumerate(jd_data['must_haves'], 1):\n",
        "    print(f\"  {i}. {skill}\")\n",
        "\n",
        "print(\"\\nâ­ Preferred Skills:\")\n",
        "for i, skill in enumerate(jd_data['nice_haves'], 1):\n",
        "    print(f\"  {i}. {skill}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Job Description Quality Assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate job description quality\n",
        "quality_result = validate_job_description_quality(sample_jd)\n",
        "\n",
        "print(\"ğŸ“Š Job Description Quality Assessment\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"ğŸ¯ Overall Score: {quality_result['quality_score']}/100\")\n",
        "print(f\"ğŸ† Quality Tier: {quality_result['quality_tier']}\")\n",
        "print(f\"ğŸ“‹ Requirements Found: {quality_result['requirements_found']}\")\n",
        "print(f\"â­ Preferences Found: {quality_result['preferences_found']}\")\n",
        "print(f\"ğŸ“ Has Title: {quality_result['has_title']}\")\n",
        "print(f\"ğŸ“ Has Location: {quality_result['has_location']}\")\n",
        "\n",
        "if quality_result['issues']:\n",
        "    print(\"\\nâš ï¸ Issues Found:\")\n",
        "    for issue in quality_result['issues']:\n",
        "        print(f\"  â€¢ {issue}\")\n",
        "\n",
        "if quality_result['suggestions']:\n",
        "    print(\"\\nğŸ’¡ Suggestions:\")\n",
        "    for suggestion in quality_result['suggestions']:\n",
        "        print(f\"  â€¢ {suggestion}\")\n",
        "\n",
        "# Create a quality breakdown chart\n",
        "quality_breakdown = {\n",
        "    'Title': 20 if quality_result['has_title'] else 0,\n",
        "    'Location': 10 if quality_result['has_location'] else 0,\n",
        "    'Requirements': min(40, quality_result['requirements_found'] * 13.33),\n",
        "    'Preferences': min(15, quality_result['preferences_found'] * 7.5),\n",
        "    'Content Detail': quality_result['quality_score'] - sum([\n",
        "        20 if quality_result['has_title'] else 0,\n",
        "        10 if quality_result['has_location'] else 0,\n",
        "        min(40, quality_result['requirements_found'] * 13.33),\n",
        "        min(15, quality_result['preferences_found'] * 7.5)\n",
        "    ])\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ“ˆ Quality Breakdown:\")\n",
        "for category, score in quality_breakdown.items():\n",
        "    bar = \"â–ˆ\" * int(score / 5) + \"â–‘\" * (20 - int(score / 5))\n",
        "    print(f\"  {category:15} {bar} {score:5.1f}/100\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‘¥ Candidate Resume Analysis\n",
        "\n",
        "Now let's analyze some candidate resumes and score them against our job requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample candidate resumes\n",
        "candidates_data = [\n",
        "    {\n",
        "        \"name\": \"Alice Johnson\",\n",
        "        \"resume\": \"\"\"\n",
        "        Alice Johnson\n",
        "        Senior Software Engineer\n",
        "        alice.johnson@email.com\n",
        "        \n",
        "        Experience:\n",
        "        â€¢ 6 years React and TypeScript development\n",
        "        â€¢ 4 years Node.js and Express.js backend\n",
        "        â€¢ PostgreSQL and MongoDB experience\n",
        "        â€¢ AWS deployment and Docker containerization\n",
        "        â€¢ Jest and Cypress testing frameworks\n",
        "        â€¢ GraphQL API development\n",
        "        â€¢ Led team of 3 developers\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Bob Smith\",\n",
        "        \"resume\": \"\"\"\n",
        "        Bob Smith\n",
        "        Full Stack Developer\n",
        "        bob.smith@email.com\n",
        "        \n",
        "        Experience:\n",
        "        â€¢ 3 years React development\n",
        "        â€¢ 2 years Node.js experience\n",
        "        â€¢ MySQL database experience\n",
        "        â€¢ Basic AWS knowledge\n",
        "        â€¢ Unit testing with Jest\n",
        "        â€¢ Python and Django background\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Carol Davis\",\n",
        "        \"resume\": \"\"\"\n",
        "        Carol Davis\n",
        "        Frontend Developer\n",
        "        carol.davis@email.com\n",
        "        \n",
        "        Experience:\n",
        "        â€¢ 7 years React and TypeScript\n",
        "        â€¢ 5 years Node.js and Express\n",
        "        â€¢ PostgreSQL and Redis experience\n",
        "        â€¢ Docker and Kubernetes deployment\n",
        "        â€¢ Comprehensive testing (Jest, Cypress, Playwright)\n",
        "        â€¢ GraphQL and REST API development\n",
        "        â€¢ Microservices architecture\n",
        "        â€¢ Team lead for 5+ developers\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create JD object for scoring\n",
        "jd = JD(\n",
        "    title=jd_data['title'],\n",
        "    location=jd_data['location'],\n",
        "    must_haves=jd_data['must_haves'],\n",
        "    nice_haves=jd_data['nice_haves']\n",
        ")\n",
        "\n",
        "print(\"ğŸ‘¥ Analyzing Candidates...\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "analyzed_candidates = []\n",
        "\n",
        "for candidate_data in candidates_data:\n",
        "    # Parse resume\n",
        "    candidate = parse_resume_to_struct(candidate_data['resume'], f\"{candidate_data['name']}.txt\")\n",
        "    \n",
        "    # Score candidate\n",
        "    score = _score_candidate(jd, candidate)\n",
        "    candidate.score = score\n",
        "    \n",
        "    analyzed_candidates.append(candidate)\n",
        "    \n",
        "    print(f\"\\nğŸ“‹ {candidate.name}\")\n",
        "    print(f\"   ğŸ“§ Email: {candidate.email}\")\n",
        "    print(f\"   ğŸ¯ Score: {score:.3f} ({score*100:.1f}%)\")\n",
        "    print(f\"   ğŸ’¼ Experience: {candidate.years_exp} years\")\n",
        "    print(f\"   ğŸ”§ Skills: {len(candidate.skills)} identified\")\n",
        "    print(f\"   ğŸ† Top Skills: {', '.join(candidate.skills[:5])}\")\n",
        "\n",
        "print(f\"\\nâœ… Analyzed {len(analyzed_candidates)} candidates successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ† Candidate Ranking and Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort candidates by score\n",
        "ranked_candidates = sorted(analyzed_candidates, key=lambda x: x.score, reverse=True)\n",
        "\n",
        "print(\"ğŸ† Candidate Rankings\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "# Create a comparison DataFrame\n",
        "comparison_data = []\n",
        "for i, candidate in enumerate(ranked_candidates, 1):\n",
        "    # Calculate skill overlap\n",
        "    must_have_matches = len(set(jd.must_haves) & set(candidate.skills))\n",
        "    nice_have_matches = len(set(jd.nice_haves) & set(candidate.skills))\n",
        "    \n",
        "    # Determine status\n",
        "    if candidate.score >= 0.7:\n",
        "        status = \"ğŸŸ¢ Excellent\"\n",
        "    elif candidate.score >= 0.5:\n",
        "        status = \"ğŸŸ¡ Good\"\n",
        "    elif candidate.score >= 0.3:\n",
        "        status = \"ğŸŸ  Fair\"\n",
        "    else:\n",
        "        status = \"ğŸ”´ Poor\"\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Rank': i,\n",
        "        'Name': candidate.name,\n",
        "        'Score': f\"{candidate.score:.3f}\",\n",
        "        'Match %': f\"{candidate.score*100:.1f}%\",\n",
        "        'Experience': f\"{candidate.years_exp}y\",\n",
        "        'Must-Have Matches': f\"{must_have_matches}/{len(jd.must_haves)}\",\n",
        "        'Nice-Have Matches': f\"{nice_have_matches}/{len(jd.nice_haves)}\",\n",
        "        'Status': status\n",
        "    })\n",
        "\n",
        "# Display as DataFrame\n",
        "df = pd.DataFrame(comparison_data)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Show detailed skill analysis for top candidate\n",
        "top_candidate = ranked_candidates[0]\n",
        "print(f\"\\nğŸ¯ Top Candidate: {top_candidate.name}\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "must_have_skills = set(jd.must_haves)\n",
        "candidate_skills = set(top_candidate.skills)\n",
        "matched_skills = must_have_skills & candidate_skills\n",
        "missing_skills = must_have_skills - candidate_skills\n",
        "\n",
        "print(f\"âœ… Matched Skills ({len(matched_skills)}/{len(must_have_skills)}):\")\n",
        "for skill in matched_skills:\n",
        "    print(f\"   â€¢ {skill}\")\n",
        "\n",
        "if missing_skills:\n",
        "    print(f\"\\nâŒ Missing Skills ({len(missing_skills)}):\")\n",
        "    for skill in missing_skills:\n",
        "        print(f\"   â€¢ {skill}\")\n",
        "\n",
        "# Show bonus skills\n",
        "nice_have_skills = set(jd.nice_haves)\n",
        "bonus_skills = candidate_skills & nice_have_skills\n",
        "if bonus_skills:\n",
        "    print(f\"\\nâ­ Bonus Skills ({len(bonus_skills)}):\")\n",
        "    for skill in bonus_skills:\n",
        "        print(f\"   â€¢ {skill}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## â“ Interview Question Generation\n",
        "\n",
        "Let's generate tailored interview questions for our top candidates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize question bank\n",
        "try:\n",
        "    qbank = LocalQuestionBank(\"../data/question_bank.csv\")\n",
        "    \n",
        "    # Generate search query from job requirements\n",
        "    search_query = \" \".join(jd.must_haves[:5])  # Top 5 skills\n",
        "    \n",
        "    print(\"â“ Generating Interview Questions\")\n",
        "    print(\"=\" * 35)\n",
        "    print(f\"ğŸ” Search Query: {search_query}\")\n",
        "    \n",
        "    # Get relevant questions\n",
        "    questions = qbank.get_relevant_questions(search_query, top_k=8)\n",
        "    \n",
        "    print(f\"\\nğŸ“‹ Generated {len(questions)} Questions:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    for i, question in enumerate(questions, 1):\n",
        "        print(f\"\\n{i}. {question}\")\n",
        "    \n",
        "    # Categorize questions by type\n",
        "    technical_keywords = ['implement', 'design', 'architecture', 'performance', 'optimize']\n",
        "    behavioral_keywords = ['experience', 'challenge', 'team', 'project', 'approach']\n",
        "    \n",
        "    technical_questions = [q for q in questions if any(kw in q.lower() for kw in technical_keywords)]\n",
        "    behavioral_questions = [q for q in questions if any(kw in q.lower() for kw in behavioral_keywords)]\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Question Breakdown:\")\n",
        "    print(f\"   ğŸ”§ Technical: {len(technical_questions)} questions\")\n",
        "    print(f\"   ğŸ‘¥ Behavioral: {len(behavioral_questions)} questions\")\n",
        "    print(f\"   ğŸ“‹ Other: {len(questions) - len(technical_questions) - len(behavioral_questions)} questions\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not load question bank: {e}\")\n",
        "    print(\"ğŸ’¡ Using sample questions instead...\")\n",
        "    \n",
        "    # Fallback sample questions\n",
        "    sample_questions = [\n",
        "        \"How would you optimize a React application for better performance?\",\n",
        "        \"Explain your approach to error handling in Node.js applications.\",\n",
        "        \"Describe your experience with TypeScript and its benefits.\",\n",
        "        \"How do you ensure code quality in a team environment?\",\n",
        "        \"Walk me through your process for debugging a production issue.\",\n",
        "        \"What's your experience with database optimization?\",\n",
        "        \"How do you approach testing in full-stack applications?\",\n",
        "        \"Describe a challenging technical problem you solved recently.\"\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nğŸ“‹ Sample Questions ({len(sample_questions)}):\")\n",
        "    for i, question in enumerate(sample_questions, 1):\n",
        "        print(f\"\\n{i}. {question}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Complete Hiring Pipeline Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive hiring summary\n",
        "print(\"ğŸ“Š Hiring Pipeline Summary\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Job summary\n",
        "print(f\"\\nğŸ“‹ Position: {jd.title}\")\n",
        "print(f\"ğŸ“ Location: {jd.location}\")\n",
        "print(f\"ğŸ¯ Quality Score: {quality_result['quality_score']}/100 ({quality_result['quality_tier']})\")\n",
        "\n",
        "# Candidate summary\n",
        "total_candidates = len(analyzed_candidates)\n",
        "qualified_candidates = len([c for c in analyzed_candidates if c.score >= 0.5])\n",
        "excellent_candidates = len([c for c in analyzed_candidates if c.score >= 0.7])\n",
        "\n",
        "print(f\"\\nğŸ‘¥ Candidates Processed: {total_candidates}\")\n",
        "print(f\"âœ… Qualified (50%+): {qualified_candidates}\")\n",
        "print(f\"ğŸ† Excellent (70%+): {excellent_candidates}\")\n",
        "print(f\"ğŸ“ˆ Success Rate: {qualified_candidates/total_candidates*100:.1f}%\")\n",
        "\n",
        "# Top candidates for interviews\n",
        "interview_candidates = ranked_candidates[:2]  # Top 2\n",
        "print(f\"\\nğŸ¯ Recommended for Interview ({len(interview_candidates)}):\")\n",
        "for i, candidate in enumerate(interview_candidates, 1):\n",
        "    print(f\"   {i}. {candidate.name} - {candidate.score*100:.1f}% match\")\n",
        "\n",
        "# Process metrics\n",
        "avg_score = sum(c.score for c in analyzed_candidates) / len(analyzed_candidates)\n",
        "max_score = max(c.score for c in analyzed_candidates)\n",
        "min_score = min(c.score for c in analyzed_candidates)\n",
        "\n",
        "print(f\"\\nğŸ“ˆ Scoring Metrics:\")\n",
        "print(f\"   ğŸ“Š Average Score: {avg_score:.3f} ({avg_score*100:.1f}%)\")\n",
        "print(f\"   ğŸ† Highest Score: {max_score:.3f} ({max_score*100:.1f}%)\")\n",
        "print(f\"   ğŸ“‰ Lowest Score: {min_score:.3f} ({min_score*100:.1f}%)\")\n",
        "\n",
        "# Recommendations\n",
        "print(f\"\\nğŸ’¡ Recommendations:\")\n",
        "if excellent_candidates == 0:\n",
        "    print(\"   â€¢ Consider widening search criteria or improving job posting\")\n",
        "if qualified_candidates < 2:\n",
        "    print(\"   â€¢ Expand candidate sourcing efforts\")\n",
        "if avg_score < 0.4:\n",
        "    print(\"   â€¢ Review job requirements - may be too restrictive\")\n",
        "else:\n",
        "    print(\"   â€¢ Strong candidate pool - proceed with interviews\")\n",
        "    print(f\"   â€¢ Schedule interviews with top {min(2, qualified_candidates)} candidates\")\n",
        "    print(\"   â€¢ Prepare technical and behavioral questions\")\n",
        "\n",
        "print(f\"\\nğŸ‰ Analysis Complete! Ready to proceed with hiring process.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ MCP Tool Schema Export\n",
        "\n",
        "For reference, here's the MCP tool schema that could be used for external integrations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display MCP tool schema\n",
        "schema = job_description_tool.get_tool_schema()\n",
        "\n",
        "print(\"ğŸ”§ MCP Tool Schema\")\n",
        "print(\"=\" * 20)\n",
        "print(json.dumps(schema, indent=2))\n",
        "\n",
        "# Save schema to file for reference\n",
        "try:\n",
        "    schema_path = Path(\"../artifacts/mcp_tool_schema.json\")\n",
        "    schema_path.parent.mkdir(exist_ok=True)\n",
        "    with open(schema_path, 'w') as f:\n",
        "        json.dump(schema, f, indent=2)\n",
        "    print(f\"\\nğŸ’¾ Schema saved to: {schema_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâš ï¸ Could not save schema: {e}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ This schema can be used for:\")\n",
        "print(\"   â€¢ External MCP server implementations\")\n",
        "print(\"   â€¢ API documentation\")\n",
        "print(\"   â€¢ Integration with AI tools (Claude Desktop, etc.)\")\n",
        "print(\"   â€¢ Custom workflow automation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Next Steps\n",
        "\n",
        "This demo showcased the core capabilities of the HR Interview Orchestrator:\n",
        "\n",
        "### âœ… What We Accomplished\n",
        "- **Job Description Analysis**: Parsed and validated JD quality\n",
        "- **Candidate Evaluation**: Scored multiple candidates against requirements\n",
        "- **Ranking & Comparison**: Identified top candidates for interviews\n",
        "- **Question Generation**: Created relevant interview questions\n",
        "- **Complete Pipeline**: End-to-end hiring workflow automation\n",
        "\n",
        "### ğŸš€ Production Usage\n",
        "To use the full system:\n",
        "\n",
        "```bash\n",
        "# Run complete pipeline\n",
        "python -m src.graph --jd data/sample_jd.md --resumes data/resumes\n",
        "\n",
        "# Parse JD only\n",
        "python -m src.graph --jd data/sample_jd.md --resumes data/resumes --parse-jd-only\n",
        "\n",
        "# Validate JD quality\n",
        "python -m src.graph --jd data/sample_jd.md --resumes data/resumes --validate-jd\n",
        "```\n",
        "\n",
        "### ğŸ”— Integration Options\n",
        "- **LangSmith**: Enable tracing with `LANGSMITH_TRACING=1`\n",
        "- **Google Integration**: Connect Gmail and Calendar\n",
        "- **Custom Workflows**: Use internal MCP tool for automation\n",
        "- **API Integration**: Build custom interfaces using the core components\n",
        "\n",
        "### ğŸ”§ Internal MCP Tool\n",
        "The notebook demonstrates the internal MCP tool that provides:\n",
        "- Structured job description parsing\n",
        "- Quality validation and scoring\n",
        "- MCP-compliant schema for future integrations\n",
        "- Standalone functionality for custom workflows\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ‰ Happy Hiring!** The HR Interview Orchestrator makes candidate screening efficient, consistent, and data-driven.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
